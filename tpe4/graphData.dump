# Created by Octave 3.8.0, Tue Apr 29 18:00:53 2014 ART <jperezcu@Javiers-MacBook-Pro.local>
# name: MAX_EPOC
# type: scalar
100


# name: train_error
# type: matrix
# rows: 1
# columns: 100
 0.1241449122426361 0.1142280764109097 0.09448811508065297 0.02622675560042187 2.37703966036254e-05 0.002449205897661903 0.004276089512529642 0.004778419082621756 0.00541287141027252 0.005762784606498637 0.005958450376887896 0.00607058195992414 0.006136697924653501 0.006006770613141018 0.00603678227339717 0.006062763462676413 0.006077204013448899 0.00608330457776733 0.006084369524591707 0.006082619894084272 0.005990938468528881 0.005955415499994598 0.005946804464762634 0.005936510437486347 0.005921117137539252 0.00590320902054994 0.005885492271373247 0.006093418524126566 0.005946977180393885 0.005900992087659013 0.005869685961191094 0.00583959736964693 0.005810649568639198 0.005784355658107585 0.006351129612772299 0.006201115114580804 0.006157812985536031 0.00611877112529371 0.006072787307484582 0.006025469632466621 0.005982279278076514 0.006866114517636731 0.006626969934880418 0.006528295095394766 0.006449260539031391 0.006381284371475521 0.006328923132752226 0.006293908803524034 0.007353222736854459 0.006989819089258141 0.0069230022044802 0.006868638601828254 0.006843196392468165 0.006847596498079908 0.006880274502075734 0.007717949578414172 0.007600659127738857 0.00759767228234539 0.007639182738748686 0.007711461561161493 0.007804217235487019 0.007908829489428735 0.008448735670518483 0.008429340432823651 0.008463076160061991 0.00851137151735369 0.008553067562574027 0.008572056499175631 0.008555572742702883 0.008694598149942988 0.008557274711828777 0.008377458564490287 0.008152128376011755 0.007902779218445606 0.007654864490488191 0.007430084752635015 0.007071538035104499 0.00693692038844644 0.00683927000882596 0.006787761799763563 0.006776592417647254 0.006795650836723029 0.006835038847140941 0.006489797659109615 0.006681727894688605 0.00681126852631064 0.00691672093881152 0.00700306758351034 0.007073013464593596 0.007129026105028105 0.006890250282095888 0.007006453615861996 0.007065497572583275 0.00710353357200473 0.007129746012015852 0.007149201739809496 0.007164930600102322 0.006942658119504756 0.006995524527931903 0.007015808983800893


# name: eta_adaptation
# type: matrix
# rows: 1
# columns: 101
 0.1 0.09975000000000001 0.09975000000000001 0.09975000000000001 0.09975000000000001 0.09975000000000001 0.09975000000000001 0.12475 0.12475 0.12475 0.12475 0.12475 0.12475 0.14975 0.149375625 0.149375625 0.149375625 0.149375625 0.149375625 0.149375625 0.174375625 0.1739396859375 0.1739396859375 0.1739396859375 0.1739396859375 0.1739396859375 0.1739396859375 0.1989396859375 0.1984423367226562 0.1984423367226562 0.1984423367226562 0.1984423367226562 0.1984423367226562 0.1984423367226562 0.2234423367226562 0.2228837308808496 0.2228837308808496 0.2228837308808496 0.2228837308808496 0.2228837308808496 0.2228837308808496 0.2478837308808496 0.2472640215536474 0.2472640215536474 0.2472640215536474 0.2472640215536474 0.2472640215536474 0.2472640215536474 0.2722640215536474 0.2715833614997633 0.2715833614997633 0.2715833614997633 0.2715833614997633 0.2715833614997633 0.2715833614997633 0.2965833614997633 0.2958419030960139 0.2958419030960139 0.2958419030960139 0.2958419030960139 0.2958419030960139 0.2958419030960139 0.320841903096014 0.320039798338274 0.320039798338274 0.320039798338274 0.320039798338274 0.320039798338274 0.320039798338274 0.345039798338274 0.3441771988424283 0.3441771988424283 0.3441771988424283 0.3441771988424283 0.3441771988424283 0.3441771988424283 0.3691771988424283 0.3682542558453223 0.3682542558453223 0.3682542558453223 0.3682542558453223 0.3682542558453223 0.3682542558453223 0.3932542558453223 0.392271120205709 0.392271120205709 0.392271120205709 0.392271120205709 0.392271120205709 0.392271120205709 0.417271120205709 0.4162279424051947 0.4162279424051947 0.4162279424051947 0.4162279424051947 0.4162279424051947 0.4162279424051947 0.4412279424051948 0.4401248725491818 0.4401248725491818 0.4401248725491818


# name: epocs
# type: scalar
100


# name: train_learning_rate
# type: matrix
# rows: 1
# columns: 100
 0 0.002680965147453083 0 0.002680965147453083 0.002680965147453083 0.002680965147453083 0.01072386058981233 0 0.002680965147453083 0.002680965147453083 0.002680965147453083 0.002680965147453083 0.008042895442359249 0.008042895442359249 0.005361930294906166 0.005361930294906166 0.008042895442359249 0.008042895442359249 0.01072386058981233 0.008042895442359249 0.002680965147453083 0.005361930294906166 0.008042895442359249 0.002680965147453083 0.005361930294906166 0.008042895442359249 0.008042895442359249 0.01072386058981233 0 0.01340482573726542 0.005361930294906166 0.008042895442359249 0.002680965147453083 0.008042895442359249 0.008042895442359249 0.002680965147453083 0.01340482573726542 0.01072386058981233 0.002680965147453083 0.005361930294906166 0.002680965147453083 0.008042895442359249 0.002680965147453083 0 0.002680965147453083 0.002680965147453083 0.002680965147453083 0.008042895442359249 0 0.002680965147453083 0.005361930294906166 0.002680965147453083 0.002680965147453083 0.002680965147453083 0.005361930294906166 0.005361930294906166 0.005361930294906166 0.002680965147453083 0.002680965147453083 0 0.005361930294906166 0.005361930294906166 0.005361930294906166 0.008042895442359249 0.005361930294906166 0.002680965147453083 0.002680965147453083 0.005361930294906166 0.005361930294906166 0.008042895442359249 0.002680965147453083 0.005361930294906166 0.002680965147453083 0.002680965147453083 0.005361930294906166 0.005361930294906166 0.008042895442359249 0.002680965147453083 0.002680965147453083 0.005361930294906166 0.005361930294906166 0.008042895442359249 0.005361930294906166 0.002680965147453083 0.008042895442359249 0.01876675603217158 0.0160857908847185 0.008042895442359249 0.0160857908847185 0.008042895442359249 0.005361930294906166 0.005361930294906166 0.005361930294906166 0.01340482573726542 0.01072386058981233 0.01072386058981233 0.01072386058981233 0.005361930294906166 0.01072386058981233 0.0160857908847185


